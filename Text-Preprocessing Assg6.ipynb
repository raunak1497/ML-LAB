{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk \n",
    "import string \n",
    "import re \n",
    "import os\n",
    "from pprint import pprint\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no of folders are: 20\n",
      "The name of folders are:\n",
      "Folder list:\n",
      " [['talk.religion.misc']\n",
      " ['soc.religion.christian']\n",
      " ['sci.med']\n",
      " ['misc.forsale']\n",
      " ['rec.autos']\n",
      " ['talk.politics.mideast']\n",
      " ['sci.electronics']\n",
      " ['talk.politics.guns']\n",
      " ['alt.atheism']\n",
      " ['comp.sys.ibm.pc.hardware']\n",
      " ['rec.sport.baseball']\n",
      " ['comp.sys.mac.hardware']\n",
      " ['talk.politics.misc']\n",
      " ['rec.motorcycles']\n",
      " ['sci.space']\n",
      " ['comp.graphics']\n",
      " ['comp.windows.x']\n",
      " ['comp.os.ms-windows.misc']\n",
      " ['rec.sport.hockey']\n",
      " ['sci.crypt']]\n"
     ]
    }
   ],
   "source": [
    "path='20_newsgroups'\n",
    "folder_list=[f for f in os.listdir(path)]\n",
    "print(\"The no of folders are:\",len(folder_list))\n",
    "print(\"The name of folders are:\")\n",
    "print(\"Folder list:\\n\",np.asarray(folder_list).reshape((len(folder_list),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', '\\n', 'There are \"basic services\" and there are \"optional services\", Dennis. Call \\n', 'waiting is an optional service, but having the number \"3\" work on one\\'s phone\\n', 'is a basic service. Just because some nutcase doesn\\'t happen to use the \"3\"\\n', 'on his phone, since none of the numbers he calls has a \"3\" in it, doesn\\'t mean \\n', 'that he has the right to demand that the phone company \"unbundle\" the charges\\n', 'for the use of each phone digit; an unbundling that would be horrendously\\n', 'inefficient because of all the billing & bookkeeping overhead. Similarly, \\n', 'abortion can be seen as a \"basic service\".\\n', '\\n', 'Furthermore, public funding of abortion SAVES money, as well as being, in the \\n', 'views of a substantial portion of the population, probably a clear majority, \\n', \"an ethical thing to do. If you don't like saving money on your taxes in that \\n\", \"way, why don't you take the taxes you save and invest in private charities \\n\", 'with programs that help reduce the NEED for abortion. If every pro-lifer did \\n', 'the same, it would create a massive economic negative feedback loop which \\n', 'would all but ELIMINATE the need for public funding of abortion. Then you \\n', 'would get your wish. And, you know what? No pro-choicer I know would stop\\n', 'you carrying out that plan. They might even HELP you with it...\\n', '\\n', '\\t\\t\\t\\t\\t\\t\\t\\t- Kevin\\n']\n"
     ]
    }
   ],
   "source": [
    "file = folder_list[0]\n",
    "files = os.listdir(os.path.join(path, folder_list[0]))\n",
    "#print(files)\n",
    "file_path = os.path.join(os.path.join(path, folder_list[0]), files[0])\n",
    "f = open(file_path,'r')\n",
    "text = f.readlines()\n",
    "meta_text =[]\n",
    "for i in text:\n",
    "    if('>' in i or ':' in i):\n",
    "        continue\n",
    "    meta_text.append(i)\n",
    "print(meta_text)\n",
    "#print(text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', '\\n', 'There', '\"basic', 'services\"', '\"optional', 'services\",', 'Dennis.', 'Call', '\\n', 'waiting', 'optional', 'service,', 'number', '\"3\"', 'work', \"one's\", 'phone\\n', 'basic', 'service.', 'Just', 'nutcase', 'happen', 'use', '\"3\"\\n', 'phone,', 'since', 'none', 'numbers', 'calls', '\"3\"', 'it,', 'mean', '\\n', 'right', 'demand', 'phone', 'company', '\"unbundle\"', 'charges\\n', 'use', 'phone', 'digit;', 'unbundling', 'would', 'horrendously\\n', 'inefficient', 'billing', 'bookkeeping', 'overhead.', 'Similarly,', '\\n', 'abortion', 'seen', '\"basic', 'service\".\\n', '\\n', 'Furthermore,', 'public', 'funding', 'abortion', 'SAVES', 'money,', 'well', 'being,', '\\n', 'views', 'substantial', 'portion', 'population,', 'probably', 'clear', 'majority,', '\\n', 'ethical', 'thing', 'do.', 'If', 'like', 'saving', 'money', 'taxes', '\\n', 'way,', 'take', 'taxes', 'save', 'invest', 'private', 'charities', '\\n', 'programs', 'help', 'reduce', 'NEED', 'abortion.', 'If', 'every', 'pro-lifer', '\\n', 'same,', 'would', 'create', 'massive', 'economic', 'negative', 'feedback', 'loop', '\\n', 'would', 'ELIMINATE', 'need', 'public', 'funding', 'abortion.', 'Then', '\\n', 'would', 'get', 'wish.', 'And,', 'know', 'what?', 'No', 'pro-choicer', 'I', 'know', 'would', 'stop\\n', 'carrying', 'plan.', 'They', 'might', 'even', 'HELP', 'it...\\n', '\\n', '\\t\\t\\t\\t\\t\\t\\t\\t-', 'Kevin\\n']\n"
     ]
    }
   ],
   "source": [
    "#stop word handling and tokenization\n",
    "from nltk.corpus import stopwords\n",
    "stopword_english=stopwords.words('english')\n",
    "text_clean=[]\n",
    "for line in meta_text:\n",
    "    word = line.split(' ')#tokenization\n",
    "    new_list =[]\n",
    "    for j in word:\n",
    "        if j not in stopword_english  and j not in string.punctuation:\n",
    "            new_list.append(j.lower())\n",
    "            text_clean.append(j)\n",
    "\n",
    "print(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n->Stemming is the process of producing morphological variants of a root/base word.\\n->There are mainly two errors in stemming – overstemming and under stemming. Over-stemming occurs when two words are\\nstemmed to same root that are of different stems. Under-stemming occurs when two words are stemmed to same root \\nthat are not of different stems.\\n->Lemmatization is the process of grouping together the different inflected forms of a word so they can be analysed\\nas a single item. Lemmatization is similar to stemming but it brings context to the words.\\n-> if a paragraph has words like cars, trains and automobile, then it will link all of them to automobile.\\n->lemmatization is preferred over Stemming because lemmatization does morphological analysis of the words.\\nOne major difference with stemming is that lemmatize takes a part of speech parameter,\\n“pos” If not supplied, the default is “noun.”\\n->Potter’s Stemmer algorithm\\nIt is one of the most popular stemming methods proposed in 1980. It is based on the idea that the suffixes in the\\nEnglish language are made up of a combination of smaller and simpler suffixes.\\n->While stemming can create words that do not actually exist, Python lemmatization will only ever result in words \\nthat do. lemmas are actual words.\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming or Lemmatization\n",
    "'''\n",
    "->Stemming is the process of producing morphological variants of a root/base word.\n",
    "->There are mainly two errors in stemming – overstemming and under stemming. Over-stemming occurs when two words are\n",
    "stemmed to same root that are of different stems. Under-stemming occurs when two words are stemmed to same root \n",
    "that are not of different stems.\n",
    "->Lemmatization is the process of grouping together the different inflected forms of a word so they can be analysed\n",
    "as a single item. Lemmatization is similar to stemming but it brings context to the words.\n",
    "-> if a paragraph has words like cars, trains and automobile, then it will link all of them to automobile.\n",
    "->lemmatization is preferred over Stemming because lemmatization does morphological analysis of the words.\n",
    "One major difference with stemming is that lemmatize takes a part of speech parameter,\n",
    "“pos” If not supplied, the default is “noun.”\n",
    "->Potter’s Stemmer algorithm\n",
    "It is one of the most popular stemming methods proposed in 1980. It is based on the idea that the suffixes in the\n",
    "English language are made up of a combination of smaller and simpler suffixes.\n",
    "->While stemming can create words that do not actually exist, Python lemmatization will only ever result in words \n",
    "that do. lemmas are actual words.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "there\n",
      "\"basic\n",
      "services\"\n",
      "\"option\n",
      "services\",\n",
      "dennis.\n",
      "call\n",
      "\n",
      "\n",
      "wait\n",
      "option\n",
      "service,\n",
      "number\n",
      "\"3\"\n",
      "work\n",
      "one'\n",
      "phone\n",
      "\n",
      "basic\n",
      "service.\n",
      "just\n",
      "nutcas\n",
      "happen\n",
      "use\n",
      "\"3\"\n",
      "\n",
      "phone,\n",
      "sinc\n",
      "none\n",
      "number\n",
      "call\n",
      "\"3\"\n",
      "it,\n",
      "mean\n",
      "\n",
      "\n",
      "right\n",
      "demand\n",
      "phone\n",
      "compani\n",
      "\"unbundle\"\n",
      "charges\n",
      "\n",
      "use\n",
      "phone\n",
      "digit;\n",
      "unbundl\n",
      "would\n",
      "horrendously\n",
      "\n",
      "ineffici\n",
      "bill\n",
      "bookkeep\n",
      "overhead.\n",
      "similarly,\n",
      "\n",
      "\n",
      "abort\n",
      "seen\n",
      "\"basic\n",
      "service\".\n",
      "\n",
      "\n",
      "\n",
      "furthermore,\n",
      "public\n",
      "fund\n",
      "abort\n",
      "save\n",
      "money,\n",
      "well\n",
      "being,\n",
      "\n",
      "\n",
      "view\n",
      "substanti\n",
      "portion\n",
      "population,\n",
      "probabl\n",
      "clear\n",
      "majority,\n",
      "\n",
      "\n",
      "ethic\n",
      "thing\n",
      "do.\n",
      "If\n",
      "like\n",
      "save\n",
      "money\n",
      "tax\n",
      "\n",
      "\n",
      "way,\n",
      "take\n",
      "tax\n",
      "save\n",
      "invest\n",
      "privat\n",
      "chariti\n",
      "\n",
      "\n",
      "program\n",
      "help\n",
      "reduc\n",
      "need\n",
      "abortion.\n",
      "If\n",
      "everi\n",
      "pro-lif\n",
      "\n",
      "\n",
      "same,\n",
      "would\n",
      "creat\n",
      "massiv\n",
      "econom\n",
      "neg\n",
      "feedback\n",
      "loop\n",
      "\n",
      "\n",
      "would\n",
      "elimin\n",
      "need\n",
      "public\n",
      "fund\n",
      "abortion.\n",
      "then\n",
      "\n",
      "\n",
      "would\n",
      "get\n",
      "wish.\n",
      "and,\n",
      "know\n",
      "what?\n",
      "No\n",
      "pro-choic\n",
      "I\n",
      "know\n",
      "would\n",
      "stop\n",
      "\n",
      "carri\n",
      "plan.\n",
      "they\n",
      "might\n",
      "even\n",
      "help\n",
      "it...\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t-\n",
      "kevin\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Stemming and lemmatization\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "   \n",
    "stem_list=[]\n",
    "ps =PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for w in text_clean:\n",
    "    rootWord=ps.stem(w)\n",
    "    stem_list.append(rootWord)\n",
    "    print(rootWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('\\n', 'JJ'), ('\\n', 'NN'), ('there', 'EX'), ('\"basic', 'JJ'), ('services\"', 'NN'), ('\"option', 'NN'), ('services\",', 'NN'), ('dennis.', 'NN'), ('call', 'NN'), ('\\n', 'NNP'), ('wait', 'NN'), ('option', 'NN'), ('service,', 'VBD'), ('number', 'NN'), ('\"3\"', 'NNP'), ('work', 'NN'), (\"one'\", 'RB'), ('phone\\n', 'JJ'), ('basic', 'JJ'), ('service.', 'NN'), ('just', 'RB'), ('nutcas', 'RB'), ('happen', 'JJ'), ('use', 'NN'), ('\"3\"\\n', 'NNP'), ('phone,', 'NN'), ('sinc', 'NN'), ('none', 'NN'), ('number', 'NN'), ('call', 'NN'), ('\"3\"', 'NNP'), ('it,', 'NN'), ('mean', 'NN'), ('\\n', 'NNP'), ('right', 'JJ'), ('demand', 'NN'), ('phone', 'NN'), ('compani', 'JJ'), ('\"unbundle\"', 'NNP'), ('charges\\n', 'NN'), ('use', 'NN'), ('phone', 'NN'), ('digit;', 'NN'), ('unbundl', 'NN'), ('would', 'MD'), ('horrendously\\n', 'VB'), ('ineffici', 'JJ'), ('bill', 'NN'), ('bookkeep', 'VB'), ('overhead.', 'JJ'), ('similarly,', 'NN'), ('\\n', 'NNP'), ('abort', 'NN'), ('seen', 'VBN'), ('\"basic', 'JJ'), ('service\".\\n', 'NN'), ('\\n', 'NNP'), ('furthermore,', 'VBZ'), ('public', 'JJ'), ('fund', 'NN'), ('abort', 'NN'), ('save', 'VBP'), ('money,', 'VBN'), ('well', 'RB'), ('being,', 'JJ'), ('\\n', 'NNP'), ('view', 'NN'), ('substanti', 'NN'), ('portion', 'NN'), ('population,', 'NN'), ('probabl', 'NN'), ('clear', 'JJ'), ('majority,', 'NN'), ('\\n', 'NNP'), ('ethic', 'JJ'), ('thing', 'NN'), ('do.', 'NN'), ('If', 'IN'), ('like', 'JJ'), ('save', 'VBP'), ('money', 'NN'), ('tax', 'NN'), ('\\n', 'NN'), ('way,', 'NNS'), ('take', 'VBP'), ('tax', 'NN'), ('save', 'NN'), ('invest', 'NN'), ('privat', 'NN'), ('chariti', 'JJ'), ('\\n', 'NNP'), ('program', 'NN'), ('help', 'NN'), ('reduc', 'VB'), ('need', 'MD'), ('abortion.', 'VB'), ('If', 'IN'), ('everi', 'JJ'), ('pro-lif', 'JJ'), ('\\n', 'NN'), ('same,', 'NN'), ('would', 'MD'), ('creat', 'VB'), ('massiv', 'JJ'), ('econom', 'NN'), ('neg', 'JJ'), ('feedback', 'NN'), ('loop', 'NN'), ('\\n', 'NNP'), ('would', 'MD'), ('elimin', 'VB'), ('need', 'VB'), ('public', 'JJ'), ('fund', 'NN'), ('abortion.', 'NN'), ('then', 'RB'), ('\\n', 'NNP'), ('would', 'MD'), ('get', 'VB'), ('wish.', 'JJ'), ('and,', 'NNS'), ('know', 'VBP'), ('what?', 'VBZ'), ('No', 'DT'), ('pro-choic', 'JJ'), ('I', 'PRP'), ('know', 'VBP'), ('would', 'MD'), ('stop\\n', 'VB'), ('carri', 'NN'), ('plan.', 'IN'), ('they', 'PRP'), ('might', 'MD'), ('even', 'RB'), ('help', 'VB'), ('it...\\n', 'VB'), ('\\n', 'JJ'), ('\\t\\t\\t\\t\\t\\t\\t\\t-', 'JJ'), ('kevin\\n', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "#pos tagging\n",
    "\n",
    "tagged=nltk.pos_tag(stem_list)\n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Regex: chunk.RegexpParser with 1 stages:\n",
      "RegexpChunkParser with 1 rules:\n",
      "       <ChunkRule: '<NN.?>*<VBD.?>*<JJ.?>*<CC>?'>\n",
      "After Chunking: (S\n",
      "  (mychunk \n",
      "/JJ)\n",
      "  (mychunk \n",
      "/NN)\n",
      "  there/EX\n",
      "  (mychunk \"basic/JJ)\n",
      "  (mychunk\n",
      "    services\"/NN\n",
      "    \"option/NN\n",
      "    services\",/NN\n",
      "    dennis./NN\n",
      "    call/NN\n",
      "    \n",
      "/NNP\n",
      "    wait/NN\n",
      "    option/NN\n",
      "    service,/VBD)\n",
      "  (mychunk number/NN \"3\"/NNP work/NN)\n",
      "  one'/RB\n",
      "  (mychunk phone\n",
      "/JJ basic/JJ)\n",
      "  (mychunk service./NN)\n",
      "  just/RB\n",
      "  nutcas/RB\n",
      "  (mychunk happen/JJ)\n",
      "  (mychunk\n",
      "    use/NN\n",
      "    \"3\"\n",
      "/NNP\n",
      "    phone,/NN\n",
      "    sinc/NN\n",
      "    none/NN\n",
      "    number/NN\n",
      "    call/NN\n",
      "    \"3\"/NNP\n",
      "    it,/NN\n",
      "    mean/NN\n",
      "    \n",
      "/NNP\n",
      "    right/JJ)\n",
      "  (mychunk demand/NN phone/NN compani/JJ)\n",
      "  (mychunk\n",
      "    \"unbundle\"/NNP\n",
      "    charges\n",
      "/NN\n",
      "    use/NN\n",
      "    phone/NN\n",
      "    digit;/NN\n",
      "    unbundl/NN)\n",
      "  would/MD\n",
      "  horrendously\n",
      "/VB\n",
      "  (mychunk ineffici/JJ)\n",
      "  (mychunk bill/NN)\n",
      "  bookkeep/VB\n",
      "  (mychunk overhead./JJ)\n",
      "  (mychunk similarly,/NN \n",
      "/NNP abort/NN)\n",
      "  seen/VBN\n",
      "  (mychunk \"basic/JJ)\n",
      "  (mychunk service\".\n",
      "/NN \n",
      "/NNP)\n",
      "  furthermore,/VBZ\n",
      "  (mychunk public/JJ)\n",
      "  (mychunk fund/NN abort/NN)\n",
      "  save/VBP\n",
      "  money,/VBN\n",
      "  well/RB\n",
      "  (mychunk being,/JJ)\n",
      "  (mychunk\n",
      "    \n",
      "/NNP\n",
      "    view/NN\n",
      "    substanti/NN\n",
      "    portion/NN\n",
      "    population,/NN\n",
      "    probabl/NN\n",
      "    clear/JJ)\n",
      "  (mychunk majority,/NN \n",
      "/NNP ethic/JJ)\n",
      "  (mychunk thing/NN do./NN)\n",
      "  If/IN\n",
      "  (mychunk like/JJ)\n",
      "  save/VBP\n",
      "  (mychunk money/NN tax/NN \n",
      "/NN way,/NNS)\n",
      "  take/VBP\n",
      "  (mychunk tax/NN save/NN invest/NN privat/NN chariti/JJ)\n",
      "  (mychunk \n",
      "/NNP program/NN help/NN)\n",
      "  reduc/VB\n",
      "  need/MD\n",
      "  abortion./VB\n",
      "  If/IN\n",
      "  (mychunk everi/JJ pro-lif/JJ)\n",
      "  (mychunk \n",
      "/NN same,/NN)\n",
      "  would/MD\n",
      "  creat/VB\n",
      "  (mychunk massiv/JJ)\n",
      "  (mychunk econom/NN neg/JJ)\n",
      "  (mychunk feedback/NN loop/NN \n",
      "/NNP)\n",
      "  would/MD\n",
      "  elimin/VB\n",
      "  need/VB\n",
      "  (mychunk public/JJ)\n",
      "  (mychunk fund/NN abortion./NN)\n",
      "  then/RB\n",
      "  (mychunk \n",
      "/NNP)\n",
      "  would/MD\n",
      "  get/VB\n",
      "  (mychunk wish./JJ)\n",
      "  (mychunk and,/NNS)\n",
      "  know/VBP\n",
      "  what?/VBZ\n",
      "  No/DT\n",
      "  (mychunk pro-choic/JJ)\n",
      "  I/PRP\n",
      "  know/VBP\n",
      "  would/MD\n",
      "  stop\n",
      "/VB\n",
      "  (mychunk carri/NN)\n",
      "  plan./IN\n",
      "  they/PRP\n",
      "  might/MD\n",
      "  even/RB\n",
      "  help/VB\n",
      "  it...\n",
      "/VB\n",
      "  (mychunk \n",
      "/JJ \t\t\t\t\t\t\t\t-/JJ)\n",
      "  (mychunk kevin\n",
      "/NN))\n"
     ]
    }
   ],
   "source": [
    "#chunking \n",
    "pattern=''' mychunk:{<NN.?>*<VBD.?>*<JJ.?>*<CC>?}'''#defining the grammar\n",
    "chunker = nltk.RegexpParser(pattern)\n",
    "print(\"After Regex:\",chunker)\n",
    "output = chunker.parse(tagged)\n",
    "print(\"After Chunking:\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-gram:  ['\\n \\n', '\\n there', 'there \"basic', '\"basic services\"', 'services\" \"option', '\"option services\",', 'services\", dennis.', 'dennis. call', 'call \\n', '\\n wait', 'wait option', 'option service,', 'service, number', 'number \"3\"', '\"3\" work', \"work one'\", \"one' phone\\n\", 'phone\\n basic', 'basic service.', 'service. just', 'just nutcas', 'nutcas happen', 'happen use', 'use \"3\"\\n', '\"3\"\\n phone,', 'phone, sinc', 'sinc none', 'none number', 'number call', 'call \"3\"', '\"3\" it,', 'it, mean', 'mean \\n', '\\n right', 'right demand', 'demand phone', 'phone compani', 'compani \"unbundle\"', '\"unbundle\" charges\\n', 'charges\\n use', 'use phone', 'phone digit;', 'digit; unbundl', 'unbundl would', 'would horrendously\\n', 'horrendously\\n ineffici', 'ineffici bill', 'bill bookkeep', 'bookkeep overhead.', 'overhead. similarly,', 'similarly, \\n', '\\n abort', 'abort seen', 'seen \"basic', '\"basic service\".\\n', 'service\".\\n \\n', '\\n furthermore,', 'furthermore, public', 'public fund', 'fund abort', 'abort save', 'save money,', 'money, well', 'well being,', 'being, \\n', '\\n view', 'view substanti', 'substanti portion', 'portion population,', 'population, probabl', 'probabl clear', 'clear majority,', 'majority, \\n', '\\n ethic', 'ethic thing', 'thing do.', 'do. If', 'If like', 'like save', 'save money', 'money tax', 'tax \\n', '\\n way,', 'way, take', 'take tax', 'tax save', 'save invest', 'invest privat', 'privat chariti', 'chariti \\n', '\\n program', 'program help', 'help reduc', 'reduc need', 'need abortion.', 'abortion. If', 'If everi', 'everi pro-lif', 'pro-lif \\n', '\\n same,', 'same, would', 'would creat', 'creat massiv', 'massiv econom', 'econom neg', 'neg feedback', 'feedback loop', 'loop \\n', '\\n would', 'would elimin', 'elimin need', 'need public', 'public fund', 'fund abortion.', 'abortion. then', 'then \\n', '\\n would', 'would get', 'get wish.', 'wish. and,', 'and, know', 'know what?', 'what? No', 'No pro-choic', 'pro-choic I', 'I know', 'know would', 'would stop\\n', 'stop\\n carri', 'carri plan.', 'plan. they', 'they might', 'might even', 'even help', 'help it...\\n', 'it...\\n \\n', '\\n \\t\\t\\t\\t\\t\\t\\t\\t-', '\\t\\t\\t\\t\\t\\t\\t\\t- kevin\\n']\n"
     ]
    }
   ],
   "source": [
    "#N-grams\n",
    "from nltk.util import ngrams\n",
    "\n",
    "def extract_ngrams(stem_list, num):\n",
    "    n_grams = ngrams(stem_list, 2)\n",
    "    return [ ' '.join(grams) for grams in n_grams]\n",
    "\n",
    "print(\"2-gram: \", extract_ngrams(stem_list, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 0 3 1 1 2 2 4 4]\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "#Clustering using K-means\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import homogeneity_score\n",
    "cluster_folder_list=[]\n",
    "\n",
    "cluster_folder_list.append(folder_list[0])\n",
    "cluster_folder_list.append(folder_list[4])\n",
    "cluster_folder_list.append(folder_list[9])\n",
    "cluster_folder_list.append(folder_list[12])\n",
    "cluster_folder_list.append(folder_list[15])\n",
    "\n",
    "#print(cluster_folder_list)\n",
    "\n",
    "new_list=[]\n",
    "for foldername in cluster_folder_list:\n",
    "    files_list = os.listdir(os.path.join(path, foldername))\n",
    "    new_list.append(os.path.join(os.path.join(path, foldername),files_list[0]))\n",
    "    new_list.append(os.path.join(os.path.join(path, foldername),files_list[1]))\n",
    "                    \n",
    "text_list = []\n",
    "for i in range(len(new_list)):\n",
    "    f = open(new_list[i],'r')\n",
    "    text1 = f.read()\n",
    "    text_list.append(text1)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(text_list)\n",
    "\n",
    "kmeans = KMeans(n_clusters=5).fit(tfidf)\n",
    "\n",
    "value = kmeans.predict(tfidf)\n",
    "\n",
    "print(value)\n",
    "j=homogeneity_score(value,new_list)\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#score between 0.0 and 1.0. 1.0 stands for perfectly homogeneous labeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
