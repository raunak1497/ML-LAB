{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'07_06_RNNs.ipynb\\n\\nAutomatically generated by Colaboratory.\\n\\nOriginal file is located at\\n    https://colab.research.google.com/drive/13_b_SHY3bBtjbB5EsodFi_RlK3eJalfS\\n\\n## Outline\\n\\n1. Introduce dataset \\n2. Data processing - Test-train split, encoding, visualisation\\n3. Basic RNN - testing inference\\n4. Evaluation and training\\n5. LSTM\\n6. GRU\\n7. Exercises\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"07_06_RNNs.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/13_b_SHY3bBtjbB5EsodFi_RlK3eJalfS\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. Introduce dataset \n",
    "2. Data processing - Test-train split, encoding, visualisation\n",
    "3. Basic RNN - testing inference\n",
    "4. Evaluation and training\n",
    "5. LSTM\n",
    "6. GRU\n",
    "7. Exercises\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-66e8011dd216>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from io import open\n",
    "import os, string, random, time, math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\"\"\"## Dataset\"\"\"\n",
    "\n",
    "languages = []\n",
    "data = []\n",
    "X = []\n",
    "y = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('name2lang.txt', 'r') as f: \n",
    "    for line in f:\n",
    "        line = line.split(',')\n",
    "        name = line[0].strip()\n",
    "        lang = line[1].strip()\n",
    "        if not lang in languages:\n",
    "            languages.append(lang)\n",
    "        X.append(name)\n",
    "        y.append(lang)\n",
    "        data.append((name, lang))\n",
    "\n",
    "n_languages = len(languages)\n",
    "\n",
    "print(languages)\n",
    "\n",
    "print(data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7b5353cd35b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\"### Train-test split\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"### Train-test split\"\"\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "\n",
    "print(X_train)\n",
    "\n",
    "print(len(X_train), len(X_test))\n",
    "\n",
    "print(languages.__len__())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### Encoding names and language\"\"\"\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "def name_rep(name):\n",
    "    rep = torch.zeros(len(name), 1, n_letters)\n",
    "    for index, letter in enumerate(name):\n",
    "        pos = all_letters.find(letter)\n",
    "        rep[index][0][pos] = 1\n",
    "    return rep\n",
    "\n",
    "def lang_rep(lang):\n",
    "    return torch.tensor([languages.index(lang)], dtype=torch.long)\n",
    "\n",
    "name_rep('Abreu')\n",
    "\n",
    "lang_rep('Portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### Basic visualisation\"\"\"\n",
    "\n",
    "count = {}\n",
    "for l in languages: \n",
    "    count[l] = 0\n",
    "for d in data:\n",
    "    count[d[1]] += 1\n",
    "\n",
    "print(count)\n",
    "\n",
    "plt_ = sns.barplot(list(count.keys()), list(count.values()))\n",
    "plt_.set_xticklabels(plt_.get_xticklabels(), rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## Basic network and testing inference\"\"\"\n",
    "\n",
    "class RNN_net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN_net, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input_, hidden):      \n",
    "        combined = torch.cat((input_, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "net = RNN_net(n_letters, n_hidden, n_languages)\n",
    "\n",
    "def infer(net, name):\n",
    "    net.eval()\n",
    "    name_ohe = name_rep(name)\n",
    "    hidden = net.init_hidden()\n",
    "    \n",
    "    for i in range(name_ohe.size()[0]):\n",
    "        output, hidden = net(name_ohe[i], hidden)\n",
    "    \n",
    "    return output\n",
    "\n",
    "output = infer(net, 'Adam')\n",
    "index = torch.argmax(output)\n",
    "print(output, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## Evaluate model\"\"\"\n",
    "\n",
    "def dataloader(npoints, X_, y_):\n",
    "    to_ret = []\n",
    "    for i in range(npoints):\n",
    "        index_ = np.random.randint(len(X_))\n",
    "        name, lang = X_[index_], y_[index_]\n",
    "        to_ret.append((name, lang, name_rep(name), lang_rep(lang)))\n",
    "    return to_ret\n",
    "\n",
    "dataloader(2, X_train, y_train)\n",
    "\n",
    "def eval(net, n_points, k, X_, y_):\n",
    "    \n",
    "    data_ = dataloader(n_points, X_, y_)\n",
    "    correct = 0\n",
    "    \n",
    "    for name, language, name_ohe, lang_rep in data_:\n",
    "        \n",
    "        output = infer(net, name)\n",
    "        val, indices = output.topk(k)\n",
    "        \n",
    "        if lang_rep in indices:\n",
    "            correct += 1\n",
    "            \n",
    "    accuracy = correct/n_points\n",
    "    return accuracy\n",
    "\n",
    "eval(net, 1000, 3, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## Training\n",
    "\n",
    "### Basic setup\n",
    "\"\"\"\n",
    "\n",
    "def train(net, opt, criterion, n_points):\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    total_loss = 0\n",
    "    \n",
    "    data_ = dataloader(n_points, X_train, y_train)\n",
    "    \n",
    "    for name, language, name_ohe, lang_rep in data_:\n",
    "\n",
    "        hidden = net.init_hidden()\n",
    "\n",
    "        for i in range(name_ohe.size()[0]):\n",
    "            output, hidden = net(name_ohe[i], hidden)\n",
    "            \n",
    "        loss = criterion(output, lang_rep)\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        total_loss += loss\n",
    "        \n",
    "    opt.step()       \n",
    "            \n",
    "    return total_loss/n_points\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "opt = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "# %%time \n",
    "# train(net, opt, criterion, 200)\n",
    "\n",
    "eval(net, 1000, 1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"### Full training setup\"\"\"\n",
    "\n",
    "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5):\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "    opt = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "    \n",
    "    loss_arr = np.zeros(n_batches + 1)\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        loss_arr[i+1] = (loss_arr[i]*i + train(net, opt, criterion, batch_size))/(i + 1)\n",
    "        \n",
    "        if i%display_freq == display_freq-1:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            print('Iteration', i, 'Top-1:', eval(net, len(X_test), 1, X_test, y_test), 'Top-2:', eval(net, len(X_test), 2, X_test, y_test), 'Loss', loss_arr[i])\n",
    "            plt.figure()\n",
    "            plt.plot(loss_arr[1:i], '-*')\n",
    "            plt.xlabel('Iteration')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.show()\n",
    "            print('\\n\\n')\n",
    "\n",
    "n_hidden = 128\n",
    "net = RNN_net(n_letters, n_hidden, n_languages)\n",
    "train_setup(net, lr=0.0005, n_batches=100, batch_size = 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## LSTM cell\"\"\"\n",
    "\n",
    "class LSTM_net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTM_net, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm_cell = nn.LSTM(input_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "    \n",
    "    def forward(self, input_, hidden):\n",
    "        out, hidden = self.lstm_cell(input_.view(1, 1, -1), hidden)\n",
    "        output = self.h2o(hidden[0])\n",
    "        output = self.softmax(output)\n",
    "        return output.view(1, -1), hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return (torch.zeros(1, 1, self.hidden_size), torch.zeros(1, 1, self.hidden_size))\n",
    "\n",
    "n_hidden = 128\n",
    "net = LSTM_net(n_letters, n_hidden, n_languages)\n",
    "train_setup(net, lr=0.0005, n_batches=100, batch_size = 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## GRU Cell\"\"\"\n",
    "\n",
    "class GRU_net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRU_net, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru_cell = nn.GRU(input_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "    \n",
    "    def forward(self, input_, hidden):\n",
    "        out, hidden = self.gru_cell(input_.view(1, 1, -1), hidden)\n",
    "        output = self.h2o(hidden)\n",
    "        output = self.softmax(output)\n",
    "        return output.view(1, -1), hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "net = LSTM_net(n_letters, n_hidden, n_languages)\n",
    "train_setup(net, lr=0.0005, n_batches=100, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
